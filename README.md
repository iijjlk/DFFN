# [Spatial-frequency Dual-Domain Feature Fusion Network for Low-Light Remote Sensing Image  Enhancement]

Official PyTorch implementation of **DFFN**.
<p align="center">
  <img src="src/fig1.png" > <br>
  Fig. 1. Comparison between the latest state-of-the-art methods and our approach.
</p>

## 📑 Content
- [TODO](#todo)
- [Dataset](#data_set)
- [Visual Results](#visual)

## <a name='todo'></a>☑️ TODO
- [x] Build the repo
- [ ] arXiv version
- [ ] Release code
- [ ] Pretrained weights&log_files
- [ ] Add Download Link for Visual Results on Common Benckmarks

## <a name='data_set'></a>🔍Dataset
We proposed two datasets iSAID-dark and darkrs. Please click [this link](null) for detailed preparation description. (Coming soon.)
<p align="center">
  <img src="src/fig5.jpg" width=80%> <br>
  Fig. 2.  Samples from the proposed iSAID-dark(Up) and darkrs(Down) dataset.
</p>

## Training & Testing 

###  Coming Soon....


## <a name='visual'></a>🔍Visual Results 

<p align="center">
  <img src="src/result_ISAIDdark.png" width=80%> <br>
  Fig. 3.   The visualization results on the iSAID-dark dataset. We present the histogram of color distribution for the images. The histograms placed in Input/GT
represent the color distribution of the GT. It can be observed that our method’s histogram is closer to the GT histogram.
</p>

<p align="center">
  <img src="src/result_DICM.png" width=80%> <br>
  Fig. 4.   The visualization results on the DICM dataset (top) and the NPE dataset (bottom).
</p>